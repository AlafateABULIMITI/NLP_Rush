# This is a readme for BERT Model

As you can see, This repository is for studying the BERT model.

For now, we have two main papers, Please read < **Attention is all you need** > first then read < **BERT:Pre-training of Deep Bidirectional Transformers for Language Understanding** >

and I have some excellent explanation of BERT: [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)

code of TF : [Transformer model for language understanding](https://www.tensorflow.org/beta/tutorials/text/transformer)

Github of Google-Research : <https://github.com/google-research/bertz>

You are welcome to add your comments and ideas for learning this model ðŸ˜œ

Time stamp:
###### Wed Jun 26 CEST 2019


I added 2 relative papers :

1. [ELMO](https://github.com/AlafateABULIMITI/NLP_Rush/blob/master/BERT/1802.05365.pdf)
2. [Universal Language Model](https://github.com/AlafateABULIMITI/NLP_Rush/blob/master/BERT/1801.06146.pdf)

Time stamp:
###### Wed Jul 3 CEST 2019